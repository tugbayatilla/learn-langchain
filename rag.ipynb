{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# RAG - Retrieval Augmented Generation"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Required Packages\n",
    "\n",
    "1. **langchain** for orchestration\n",
    "2. **openai** for the embedding model and LLM\n",
    "3. **weaviate-client** for the vector database"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T15:10:43.854764Z",
     "start_time": "2024-04-18T15:10:43.851082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare Question\n",
    "question = 'how can langsmith help with testing?'"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T15:10:44.133607Z",
     "start_time": "2024-04-18T15:10:44.127599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Imports\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T15:10:44.381993Z",
     "start_time": "2024-04-18T15:10:44.376056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load Environment variables\n",
    "load_dotenv()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preparation"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Collect and load data"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T15:10:45.720462Z",
     "start_time": "2024-04-18T15:10:45.056249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/langchain-ai/langchain/master/docs/docs/modules/state_of_the_union.txt\"\n",
    "loader = WebBaseLoader(url)\n",
    "documents = loader.load()\n",
    "len(documents)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Chunk Documents"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T15:10:47.312615Z",
     "start_time": "2024-04-18T15:10:47.302134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "len(chunks)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Embed and store the chunks"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T15:10:49.534047Z",
     "start_time": "2024-04-18T15:10:48.675068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Weaviate\n",
    "import weaviate \n",
    "\n",
    "client = weaviate.connect_to_embedded()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started /Users/tugbay/.cache/weaviate-embedded: process ID 26631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-04-18T17:10:49+02:00\"}\n",
      "{\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2024-04-18T17:10:49+02:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2024-04-18T17:10:49+02:00\"}\n",
      "{\"level\":\"warning\",\"msg\":\"Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.\",\"time\":\"2024-04-18T17:10:49+02:00\"}\n",
      "{\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50050\",\"time\":\"2024-04-18T17:10:49+02:00\"}\n",
      "{\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://127.0.0.1:8079\",\"time\":\"2024-04-18T17:10:49+02:00\"}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T14:53:38.960370Z",
     "start_time": "2024-04-18T14:53:34.582079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vectorstore = Weaviate.from_documents(\n",
    "    client = client,    \n",
    "    documents = chunks,\n",
    "    embedding = OpenAIEmbeddings(),\n",
    "    by_text = False\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tugbay/Projects/ai/langchain-learn/.venv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n",
      "{\"level\":\"info\",\"msg\":\"Created shard langchain_67e53d2cc73a4662ad80fa437b16dcfd_VWpKMhy0VSaH in 1.537666ms\",\"time\":\"2024-04-18T16:53:34+02:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-04-18T16:53:34+02:00\",\"took\":58291}\n",
      "/Users/tugbay/Projects/ai/langchain-learn/.venv/lib/python3.12/site-packages/pydantic/main.py:1051: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.7/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Execution"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 1: Retrieve"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T14:54:05.998964Z",
     "start_time": "2024-04-18T14:54:05.995421Z"
    }
   },
   "cell_type": "code",
   "source": "retriever = vectorstore.as_retriever()",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 2: Augment"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T14:54:41.747Z",
     "start_time": "2024-04-18T14:54:41.648001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "print(prompt)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the question. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\\n\"))]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 3: Generate"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T14:58:33.436380Z",
     "start_time": "2024-04-18T14:58:31.015658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from langchain.chat_models import ChatOpenAI -- deprecated\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever,  \"question\": RunnablePassthrough()} \n",
    "    | prompt \n",
    "    | llm\n",
    "    | StrOutputParser() \n",
    ")\n",
    "\n",
    "query = \"What did the president say about Justice Breyer\"\n",
    "rag_chain.invoke(query)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tugbay/Projects/ai/langchain-learn/.venv/lib/python3.12/site-packages/pydantic/main.py:1051: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.7/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The president honored Justice Breyer for his service and dedication to the country. He mentioned nominating Judge Ketanji Brown Jackson to continue Justice Breyer's legacy of excellence. The president highlighted Justice Breyer's background and the importance of nominating someone to the Supreme Court.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
